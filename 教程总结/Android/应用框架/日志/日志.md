
https://zhuanlan.zhihu.com/p/615102614
Log4J、Log4J2和LogBack的关系
Log4J最早
LogBack和SLF4J用来替代Log4J
    SLF4J的全称是Simple Logging Facade for Java，slf4j是门面模式的典型应用，用于整合不同的日志系统，不负责具体的实现
Log4J2借鉴logBack


日志策略  日志上报的策略
策略是服务器下发的，都是针对单一设备做的限制，批量上传条数、日志有效时间、是否允许上传、最大上传条数、允许上传日志级别等等。
用于业务数据存储的话，建议业务上自己实现，这边sdk我们一般用作日志观察、属于大数据性质的系统，所以为了性能和稳定性会对准确度有一定取舍
例如：
每天每台设备最多上传20000条, 超过后将会长传失败或者不再上传
一次上传日志的个数是5条，不够5条会等待日志达到5条再上传
日志使用接口方式上传，每条日志的大小推荐是小于2KB
本地日志的有效期是3天，超过三天没有上传就会被丢弃
根据deviceId来确定单个设备
设定日志每天的上传数量时，需要考虑用户长时间不重启设备，此时的日志计数


日志库
https://github.com/apache/logging-log4j2
https://github.com/qos-ch/slf4j


全链路日志的设计  收集android，unity，h5
1 本地日志  数据量大，不上报  可上报某一部分，或者动态下发开关，待完善
在APP中增加相关彩蛋，可以考虑测试时默认打开。
前期先不考虑文件压缩，后续链路建设完成后需要进行输出文件压缩
2 收集关键路径  android与unity,与h5 通信
3 自动解析 分析异常，对比以前的log
例如查看消息是否传输到位，是否在某链路断线。   根据场景关键链路标记进行检测
查看函数的收参是否超出限制之类的


https://juejin.cn/post/6999421899021221901#heading-5
uuid生成：
1  UUID.randomUUID().toString()
2  使用MDC存储
MDC（Mapped Diagnostic Contexts）：映射调试上下文，主要用在做日志链路跟踪时，动态配置用户自定义的一些信息，比如RequestId、TraceId等等
内部使用ThreadLocal，并配置InheritableThreadLocal  父子线程共用值


https://juejin.cn/post/7124598702307541023
传统的ELK方案需要开发者在编写代码时尽可能全地打印日志，再通过关键字段从ES中搜集筛选出与业务逻辑相关的日志数据，进而拼凑出业务执行的现场信息。然而该方案存在如下的痛点：
日志搜集繁琐：虽然ES提供了日志检索的能力，但是日志数据往往是缺乏结构性的文本段，很难快速完整地搜集到全部相关的日志。
日志筛选困难：不同业务场景、业务逻辑之间存在重叠，重叠逻辑打印的业务日志可能相互干扰，难以从中筛选出正确的关联日志。
日志分析耗时：搜集到的日志只是一条条离散的数据，只能阅读代码，再结合逻辑，由人工对日志进行串联分析，尽可能地还原出现场。

为了解决复杂链路排查困难的问题，“分布式会话跟踪方案”诞生。该方案的理论知识由Google在2010年《Dapper》论文中发表，随后Twitter开发出了一个开源版本Zipkin
https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf
通过一个分布式全局唯一的id（即traceId），将分布在各个服务节点上的同一次请求串联起来，还原调用关系、追踪系统问题、分析调用数据、统计系统指标。分布式会话跟踪，
  是一种会话级别的追踪能力
缺点：
(1) 无法同时追踪多条调用链路 多个子场景共用一个traceId
  一个业务调用两次接口，初审和复审，需要共用一个id
(2) 无法准确描述业务逻辑的全景 不能覆盖未执行的业务
(3) 无法聚焦于当前业务系统的逻辑执行  日志是整个复杂的场景，大部分时间聚焦于当前业务即可
链路定义+链路染色+链路上报+链路存储
链路定义:使用dsl描述(json)，链路通常由多个逻辑节点，按照一定的业务规则组合而成，业务规则即各个逻辑节点之间存在的执行关系，包括串行、并行、条件分支。
```
{      "nodeName": "A",      "nodeType": "rpc"    },    {      "nodeName": "Fork",      "nodeType": "fork"
```

链路染色：在链路执行过程中，通过透传串联标识，明确具体是哪条链路在执行，执行到了哪个节点
链路唯一标识 = 业务标识 + 场景标识 + 执行标识
节点唯一标识 = 链路唯一标识 + 节点名称 （两个标识共同决定“某个业务场景下的某次执行中的某个逻辑节点”）

链路上报：在链路执行过程中，将日志以链路的组织形式进行上报，实现业务现场的准确保存

链路存储：将链路执行中上报的日志落地存储，并用于后续的“现场还原”
业务日志上报：
```
 // 替换前：原日志上报
  LOGGER.error("update struct failed, param:{}", GsonUtils.toJson(structRequest), e);
  // 替换后：全链路日志上报
  TraceLogger.error("update struct failed, param:{}", GsonUtils.toJson(structRequest), e);
```
节点日志上报：支持API、AOP两种上报方式，灵活且成本低
```
public Response realTimeInputLink(long contentId) {
    // 链路开始：传递串联标识（业务标识 + 场景标识 + 执行标识）
    TraceUtils.passLinkMark("contentId_type_uuid");
    // ...
    // 本地调用(API上报节点日志)
    TraceUtils.reportNode("contentStore", contentId, StatusEnums.RUNNING)
    contentStore(contentId);
    TraceUtils.reportNode("contentStore", structResp, StatusEnums.COMPLETED)
    // ...
    // 远程调用
    Response processResp = picProcess(contentId);
    // ...
  }
  // AOP上报节点日志
  @TraceNode(nodeName="picProcess")
  public Response picProcess(long contentId) {
    // 图片处理业务逻辑
    // 业务日志数据上报
    TraceLogger.warn("picProcess failed, contentId:{}", contentId);
  }
```
链路可视化：根据链路定义的业务节点和上报的节点，进行可视化展示


