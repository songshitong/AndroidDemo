
http://gityuan.com/2015/12/06/linux_epoll/
 select poll epoll的源码
//todo http://gityuan.com/2019/01/06/linux-epoll/    
http://gityuan.com/2019/01/05/linux-poll-select/ 

select/poll/epoll都是IO多路复用机制，可以同时监控多个描述符，当某个描述符就绪(读或写就绪)，
则立刻通知相应程序进行读或写操作。本质上select/poll/epoll都是同步I/O，即读写是阻塞的

在Linux下设计并发网络程序，向来不缺少方法，比如典型的Apache模型（Process Per Connection，简称PPC），
TPC（Thread PerConnection）模型，以及select模型和poll模型,epoll模型
//todo 
多路复用
后台的程序只需要 1 个就可以负责管理多个 fd 句柄，负责应对所有的业务方的 IO 请求。这种一对多的 IO 模式我们就叫做 IO 多路复用。
多路是指？多个业务方（句柄）并发下来的 IO 。 复用是指？复用这一个后台处理程序

select
int select (int maxfd, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
maxfd：代表要监控的最大文件描述符fd+1
writefds：监控可写fd
readfds：监控可读fd
exceptfds：监控异常fd
timeout：超时时长
    NULL，代表没有设置超时，则会一直阻塞直到文件描述符上的事件触发
    0，代表不等待，立即返回，用于检测文件描述符状态
    正整数，代表当指定时间没有事件触发，则超时返回
select函数监控3类文件描述符，调用select函数后会阻塞，直到描述符fd准备就绪（有数据可读、可写、异常）或者超时，函数便返回。 
当select函数返回后，可通过遍历描述符集合，找到就绪的描述符。
select缺点
文件描述符个数受限：单进程能够监控的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义增大上限，
   但同样存在效率低的弱势;
性能衰减严重：IO随着监控的描述符数量增长，其性能会线性下降;


poll    poll [pəʊl] 投票;民意调查;民意测验;选举投票;计票;投票数
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
其中pollfd表示监视的描述符集合，如下
struct pollfd {
int fd; //文件描述符
short events; //监视的请求事件
short revents; //已发生的事件
};
pollfd结构包含了要监视的event和发生的event，并且pollfd并没有最大数量限制。 和select函数一样，当poll函数返回后，
可以通过遍历描述符集合，找到就绪的描述符
poll缺点

从上面看select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。同时连接的大量客户端在同一时刻可能
  只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其性能会线性下降。

epoll
epoll是在内核2.6中提出的，是select和poll的增强版。相对于select和poll来说，epoll更加灵活，没有描述符数量限制。
epoll使用一个文件描述符管理多个描述符，将用户空间的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。
epoll机制是Linux最高效的I/O复用机制，在一处等待多个文件句柄的I/O事件。

select/poll都只有一个方法，epoll操作过程有3个方法，分别是epoll_create()， epoll_ctl()，epoll_wait()。
epoll_create
int epoll_create(int size)；
功能：用于创建一个epoll的句柄，size是指监听的描述符个数， 现在内核支持动态扩展，该值的意义仅仅是初次分配的fd个数，
  后面空间不够时会动态扩容。 当创建完epoll句柄后，占用一个fd值.
ls /proc/<pid>/fd/  //可通过终端执行，看到该fd
使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽

epoll_ctl
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
功能：用于对需要监听的文件描述符(fd)执行op操作，比如将fd加入到epoll句柄。
epfd：是epoll_create()的返回值；
op：表示op操作，用三个宏来表示，分别代表添加、删除和修改对fd的监听事件；
    EPOLL_CTL_ADD(添加)
    EPOLL_CTL_DEL(删除)
    EPOLL_CTL_MOD（修改）
fd：需要监听的文件描述符；
epoll_event：需要监听的事件，struct epoll_event结构如下：
```
struct epoll_event {
    __uint32_t events;  /* Epoll事件 */
    epoll_data_t data;  /*用户可用数据*/
  };
```
events可取值：(表示对应的文件描述符的操作)
EPOLLIN ：可读（包括对端SOCKET正常关闭）；
EPOLLOUT：可写；
EPOLLERR：错误；
EPOLLHUP：中断；
EPOLLPRI：高优先级的可读（这里应该表示有带外数据到来）；
EPOLLET： 将EPOLL设为边缘触发模式，这是相对于水平触发来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后就不再监听该事件


epoll_wait
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
功能：等待事件的上报
epfd：等待epfd上的io事件，最多返回maxevents个事件；
events：用来从内核得到事件的集合；
maxevents：events数量，该maxevents值不能大于创建epoll_create()时的size；
timeout：超时时间（毫秒，0会立即返回）。
   该函数返回需要处理的事件数目，如返回0表示已超时

对比
1）在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()
来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，
当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)

epoll优势

监视的描述符数量不受限制，所支持的FD上限是最大可以打开文件的数目，具体数目可以cat /proc/sys/fs/file-max查看，
一般来说这个数目和系统内存关系很大，以3G的手机来说这个值为20-30万。

IO性能不会随着监视fd的数量增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的，只有就绪的fd才会执行回调函数。

如果没有大量的空闲或者死亡连接，epoll的效率并不会比select/poll高很多。但当遇到大量的空闲连接的场景下，epoll的效率大大高于select/poll



inotify
INotify是Linux内核所提供的一种文件系统变化通知机制。它可以为应用程序监控文件系统的变化，如文件的新建、删除、读写等。
INotify机制有两个基本对象，分别为notify对象与watch对象，都使用文件描述符表示。

inotify对象对应一个队列，应用程序可以向inotify对象添加多个监听。当被监听的事件发生时，可以通过read函数从inotify对象中
将事件信息读取出来。
Inotify对象可以通过以下方式创建:
int inotifyFd=inotify_init();

而watch对象则用来描述文件系统的变化事件的监听。它是一个二元组，包括监听目标和事件掩码两个元素。监听目标是文件系统的一个路径，
可以是文件也可以是文件夹。而事件掩码则表示了需要监听的事件类型，掩码中的每一位代表一种事件。可以监听的事件种类 很多，其中就
包括文件的创建(IN_CREATE)与删除(IN_DELETE)。
其他事件种类
```
IN_ACCESS：文件被访问
IN_MODIFY：文件被修改
IN_ATTRIB，文件属性被修改
IN_CLOSE_WRITE，以可写方式打开的文件被关闭
IN_CLOSE_NOWRITE，以不可写方式打开的文件被关闭
IN_OPEN，文件被打开
IN_MOVED_FROM，文件被移出监控的目录
IN_MOVED_TO，文件被移入监控着的目录
IN_CREATE，在监控的目录中新建文件或子目录
IN_DELETE，文件或目录被删除
IN_DELETE_SELF，自删除，即一个可执行文件在执行时删除自己
IN_MOVE_SELF，自移动，即一个可执行文件在执行时移动自己
```
以下代码即可将一个用于监听输入设备节点的创建与删除的
watch对象添加到inotify对象中:
```
int wd=inotify_add_watch(inotifyFd,“/dev/input”,INCREATE|IN_DELETE);
```
完成上述watch对象的添加后，当/dewinput/下的设备节点发生创建与删除操作时，都会将相应的事件信息写入inotifyFd所描述的inotify对象中，
此时可以通过read函数从inotifyFd描述符中将事件信息读取出来。
事件信息使用结构体inotify_event进行描述:
struct inotify_event {
__s32 wd; /* 事件 对 应 的 Watch 对 象 的 描述 符 */
__u32 mask; /* 事件 类 型 ， 例 如 文件 被 删除 ， 此 处 值 为 IN_DELETE */
__u32 cookie;
__u32 len; /* name 字 段 的 长 度 */
char  name [0] ; /* 可 变 长 的 字段 ， 用 于 存储 产生 此 事件 的 文件 路 径 */
}
当监听事件发生时，可以通过如下方式将一个或多个未读取的事件信息读取出来:
size_t len=read(inotifyFd，events_buf，BUF_LEN);
其中events_buf是inotify_event的数组指针，能够读取的事件数量取决于数组的长度。成功读取事件信息后，便可根据inotify_event
结构体的字段判断事件类型以及产生事件的文件路径。
通过INotify机制避免了轮询文件系统的麻烦，但是还有一个问题，INotify机制并不是通过回调的方式通知事件，而需要使用者主动
 从inotify对象中进行事件读取。那么何时才是读取的最佳时机呢?这就需要借助Linux的另一个优秀的机制Epoll了