2022-05-14
测不准原理:
我们生活的这个世界的确是没有绝对客观的存在,人类观察世界的方式和角度和这个世界对待我们的方式和方法
会从物理学的层面影响彼此,我们能真正观察到的东西其实是客观世界和主观想象之间的结合
信息:
人类之间分享知识是一件可以为这个世界创造纯粹增量的事情
信息熵(InformationEntropy)就是描述一个东西的不确定程度的量
信息量就是用来把信息熵消除掉的信息所需要的能量,单位:比特
可能性越不平均,信息熵就越低给我们的启示是在日常生活中模棱两可的态度是最没信息量的
无论信息论和热力学都从不同的侧面说明了一个道理不做选择,随波逐流或者平均分配注意力就会增加整个系统的无序性
霍夫曼编码
为了提高效率,我们应该把生活中最重要的资源分配给人生中最高频出现的场景
配合奥卡姆剃刀   大刀阔斧地做减法+围绕关键领域饱和配置
1 工作区域和阅读区域要大于娱乐区域(电视等)
1 一天只吃早饭,午饭,9点前早睡    
2 花尽可能多的钱在手机和电脑上  
3 花尽可能少的钱在衣服上,女性随意
帧间压缩:
通过关注信息增量而不是关注信息存量来极大的提升效率
关注变化,忽略重复,可以使我们的学习效率提升N倍
做任何事情,起步的时候先花时间把基本功练扎实是重要的,因为基本功越扎实,后面不断前进就可以只关注增量,大大提升效率
例如快速读书:如果你对很多人类关键的学科知识都建立了认知框架,那么新书的增量阅读也就非常快了,可以迅速理解
冗余度:
1.冗余并不一定是坏东西,在工程领域,他可以保证系统运作安全,在表达上,他能更好的服务于人类的认知习惯
2.时代在进步,人类习惯接受的冗余度也在减少,所以我们越来越需要掌握去除冗余度的方法

分析框架的作用:类似关键第一帧为后续研究增量信息提供基础
画分析框架通常使用这样的三步法:
1.先把关键概念零散列出来,这种罗列不需要顺序,只要觉得重要就写上去,这一步就类似于建立了很多概念的卡片
2.寻找概念卡片之间的关联,对他们进行分类,连接,同时拿掉一些信息等价的卡片
3.套用和矫正  会议我在大脑中已经建立的那些思维模型,然后对他们进行套用和矫正,最后形成一个属于这一次阅读内容的新的分析框架


三条重要公式   信息熵   霍夫曼编码   帧间压缩算法  互信息  冗余度

开篇
把信息 信息产业 互联网划等号是个很大的误解
信息是宇宙的固有组成部分,宇宙大爆炸开始信息和能量一起出现,世界上任何事物都可以用信息的方式来量化
张首诚教授:对于人类文明来讲有三条最重要的公式E=mc方描述的是物质和能量的关系
第二条是香农的信息熵公式描述的是信息如何变化   H(x) = E[I(xi)] = E[ log(2,1/P(xi)) ] = -∑P(xi)log(2,P(xi)) (i=1,2,..n)
第三条海森堡测不准原理 ΔxΔp≥h/4π 描述的是科学的边界

三条重要公式:
E=mc方 将物质和能量同一了在一起  E是能量,m是物质 c是光速,这条公式最神奇的地方是让我们意识到能量和物质是相通的,这是科学思维最让人震撼的
地方之一,他可以将两个完全不同的东西通过抽象的数学公式简化成一个东西进行衡量,测算,通过化繁为简,人类可以更好的改变世界和理解世界的
的杠杆
第一条公式和第二条加起来就是能量,信息,物质
测不准原理属于量子力学的范畴,实际再告诉我们科学的边界在哪里,我们本来认为我们的仪器越来越好,理论上可以把基本粒子的位置和速度测算的越来越准确,
  最终完全掌握他们的行踪,但是第三条公式就告诉我们不论科学怎么发展,我们永远都不可能精确地测算基本粒子的状态,因为我们观察粒子这件事情本身
  就会改变它的行为.
  这个在宏观世界比较费解,比如我站在五层楼高的楼顶观察路上的车辆,理论上讲,如果天气够好,视力没问题,我可以非常清晰的看到每一辆车的行进轨迹,
  颜色和大小,不可能说这个车我不看他的时候他在第一个车道,一看他就变到第二个车道了,不看他他又回到第一个车道了,
  但在微观世界,我们观察一个基本粒子,我们需要把一个光子打在他身上,那么就这么一个行为,可以改变基本粒子的行进轨迹,
  因为这个粒子会吸收光子的动量,而在瞬间改变自己的运动状态,通俗点说就是我们的观察改变了客观世界
第三条公式给我们的启发是,我们生活的这个世界的确是没有绝对客观的存在,人类观察世界的方式和角度和这个世界对待我们的方式和方法
会从物理学的层面影响彼此,我们能真正观察到的东西其实是客观世界和主观想象之间的结合

能量和信息的差别:能量守恒,但信息不守恒
能量守恒定律:能量不会凭空产生凭空消失,只会从一个形态转换到另一个形态,或者从一个物体转移到另一个物体
信息没有这个特性,他可以被无限复制和分享,不存在一个人多了另一个人就少了的特点,这给我一个启示是人类之间分享知识是一件可以为这个
世界创造纯粹增量的事情.你分享了知识,你的知识并没有减少,但是别人的知识却增加了

信息论是信息时代非常必要了解的知识,信息论自诞生以来不止被应用到信息产业,过去半个多世纪里在统计物理,计算科学,投资学甚至哲学很多许多科学里面
都是奠基性贡献,可以说信息论是当代科学重要的一块基石
为什么信息论没有成为每一个人的必修课呢? 答案是信息论太抽象了.up主在大二的时候准备用两周的时间,通过几本借来的入门了解一下,结果两天就放弃了,
因为这门科学需要掌握其他学科的基础知识非常多,比如统计学,概率论,微积分,线性代数,计算机科学,物理学等等,这里面的数学连读数学系的人都觉得
晦涩,对于非理科类的同学来说肯定更难理解
所以今天绕开所有的数学公式,只讲核心原理

第一个话题 信息是怎么衡量的
如果我们想衡量物质->使用质量,其实衡量信息也可以用信息量(Amount of information),但是对于信息量的衡量方法大部分人不清楚,也就是第二条著名的信息熵公式,
他是整个信息论的基础
熵在热力学课讲过是代表分子的混乱程度,系统的不确定性,香农就化用到信息的领域,信息熵(InformationEntropy)就是描述一个东西的不确定程度的量,说人话就是
搞清楚一件事情的难度
假如你去抽奖,红色代表中奖,如果你知道盒子里面只有一个球且是红色,你要搞清楚是否中奖毫无难度,所以你面对的信息熵就是零,但盒子里面
有1万个球,其中只有一个红色球,那么不确定性就非常大了,这个时候你要搞清楚是否中奖难度极大,这意味着抽奖盒里面的信息熵非常大
再比如我们有个盲盒,假如盒子外面就印着皮卡丘的样子,那么他的不确定就很小,信息熵也接近于零,但如果盲盒系有12个娃娃,而且有的娃娃出现概率高,
有的概率低,那么你要搞清楚打开是哪一款难度就陡然增大了,这个盒子的信息熵就远大于皮卡丘盒子的信息熵
可见影响信息熵的因素有:
1.可能出现的娃娃款式数量越多,信息熵就越大
2.在娃娃款式数量不变的情况下,如果每一款出现的概率是一样的,这个时候信息熵最大
3.如果其中一款出现的概率很大,比如10次里面有9次都是他, 那么就会大大降低信息熵

假如有100个盒子,分别装蓝色皮卡丘和黄色皮卡丘,那么有三种情况第一种情况是一百个盒子都是蓝色款,第二种情况是一百个盒子装的是黄色款,
第三种情况是50个盒子装黄色,50个装蓝色
跨学科_信息论_皮卡丘信息熵1.jpg
第一种情况和第二种情况信息熵都为0,因为百分之百都是同一种颜色,这个时候没有不确定性,但是第三种情况不确定性达到最高,信息熵最大,
任何一个盒子蓝色黄色的概率都是50
在图中抛物线函数,假如有60个蓝色,40个黄色,他的信息熵会比50低一点,也就是说可能性越不平均,信息熵就越低

信息量就是用来把信息熵消除掉的信息所需要的能量,香农定义了一个单位:比特.
可能性越不平均,信息熵就越低给我们的启示是在日常生活中模棱两可的态度是最没信息量的,比如出去吃饭,别人问你吃什么,你说随便,这其实
是你给出去的可能性正处于信息熵函数的正中间位置,创造了信息熵的最大值,消除它需要对方提供最大的信息量,如果你能说不吃辣,那么立马
可以把函数在横轴上右移,减少信息熵,进一步你还能够直接说自己想要吃哪家店什么菜,等于把信息熵推到了最小的一边
跨学科_信息论_吃饭的信息熵.jpg
无论信息论和热力学都从不同的侧面说明了一个道理不做选择,随波逐流或者平均分配注意力就会增加整个系统的无序性,如何聪明的分配
我们的资源和注意力,这就要讲到信息论的另一个重要模型霍夫曼编码(Huffman Coding)

霍夫曼编码是一种编码方法,如果我们可以把较短的编码分配给高频出现的词汇,而把较长的编码分配给低频出现的词汇,整体而言,我们用
编码来表达语言的时候就可以实现效率的最优化
古代战场上一个传令兵只能用两种旗来传递指令,一种是红旗,一种是绿旗,这里最简单的指令是单举一次红单举一次绿或者同时举起红和绿,
一般来讲这三种情况应该拿来表示战场上最经常出现的三种行动方案,单举一次红旗代表全体进攻,单举一次绿旗代表全体撤退,同时举起代表
原地待命而不应该是反过来用这三种最简单指令去代表类似盾牌手原地待命,骑兵绕到攻击敌军后方,步兵进行埋伏,相对不常见特别复杂的行动方案.
要不然传令的过程就太麻烦了
我们也听过发电报的莫尔斯电码,编码的原理就是这个思路,他是由点和长线这两种信号组成的比如说一点一横代表A,两横一点代表Z,用这种
复杂的方式拼写单词非常费劲,为了节省发报员的工作量,就必须把简单的代码分配给最高频使用的字母,对于T E S I N A这样使用频率很高的
字母要分配最简单的代码资源,比如E是一个点,S是三个点,而对于Q Y X V L这样使用频率比较低的字母分配相对复杂的代码资源,比如说L是一点
一横加两点,这样的方式就很明显比按照26个字母从头到尾顺序安排代码资源要合理的多
跨学科_信息论_莫尔斯电码.jpg
给我们的启发是为了提高效率,我们应该把生活中最重要的资源分配给人生中最高频出现的场景.了解这个原理对于安排家具的位置对up主有很大的启发:
因为在家从来不看电视,所以家里的电视和沙发的空间对我来说就是极度低频的场景,但是工作区和阅读区却非常高频,所以以前租房子的时候
经常发现传统的出租屋都是把工作区设计得很小,甚至根本没有,然后把电视区搞的大大的,于是住进去之后第一件事就是把电视区改造成工作区
加阅读区,这样就把最重要的资源分配给了最高频的场景.
信息论反复告诉我们模棱两可,平均用力是一种相对无效的资源配置方式,这侧面印证了14世纪提出的一种哲学奥卡姆剃刀(Occam`s Razor)
意思是如无必要勿增实体,将奥卡姆剃刀和霍夫曼编码结合起来,可以得出安排人生效率的好方法:大刀阔斧地做减法+围绕关键领域饱和配置,
这是我本人采用的一种人生哲学,比如在霍夫曼编码的启发下花了一年的时间非常认真的研究过自己生活中那些最高频的场景,比如吃饭,睡觉,
运动,呼吸,工作,娱乐,排便,这些东西都在做但是大多数人只是凭借本能在处理的事情,所以由于没有刻意的去安排他们,这些东西通常隐藏了
大量的bug,但是我们却没有意识到这是一个巨大资源浪费.
例如使用奥卡姆剃刀的场景:现在一日三餐已经是人类的基本常识,这件事情有没有改进空间呢?up经过长期实验发现他其实可以一天只吃两顿
一顿早餐,一顿午餐不吃晚餐,这种饮食方式在古代东方历史上是有一些记载的,例如道家过午不食,更远的时代,两万年前,我们的原始人祖先
也并没有一日三餐的习惯,我们现在的身体结构和当时差不多,一日三餐显然不是完全必要的,所以我一天只吃两顿饭,这比普通人每天多两个小时的
晚餐时间,而且使得我晚上有更多的清醒工作的时间,还可以使得我晚上9点前就可以结束当天的工作,然后可以适当的放松,进行睡前准备,
而且一天只吃两顿,这两顿饭就有更充足的时间去吃,而且吃的更好,这是典型的围绕关键领域饱和配置资源的例子
不过提醒一下这个方法可能对大多数人也是不适用的,因为很多人习惯晚上安排大量的工作,晚上的消耗非常大就必须吃晚餐了,大家不要被
我这个早睡党误导了,还是按自己的节奏来,只是为了说明奥卡姆和霍夫曼的实际应用
再比如我在手机和笔记本电脑上从来都是饱和攻击,尽我所能购买质量最好的产品,因为这两样东西对我来说使用的频率实在太高了,想想我们
每天打开手机的次数和使用电脑工作的时长,就明白在这两样东西上花钱是非常值得的与之相对,我们在衣服上的花销非常值得反思,因为很多
衣服一年就就穿那么几次,他是典型的低频场景,所以在衣服上配置过多的金钱绝对是种资源的浪费,当然,对很多女性来讲不是这样的,因为
服装鞋帽对她们不止是一种工具还是一种美的信仰和自我表达的需求,这就不在信息论的讨论范围了,这涉及到心理学,社会学,美学等...

帧间压缩算法(InterFrame compression)
所谓的帧就是我们看视频的时候影像动画最小单位的单幅静止画面,把他们连续起来就会形成运动画面也就是今天看到的视频,
视频是一定要压缩的否则今天的网络和带宽根本承受不了,假设一个两小时未压缩的高清视频1920*1080P的电影,由于人眼的
特性大概每秒需要能够刷新20帧以上才会感觉流畅,而之前电影这个数字一般是24,假设是25好算一点,在假设用的RGB三原色,
一个像素占三个字节,2小时*60分钟*60秒*25帧*1920*1080像素*3(每像素字节数)约等于1119.8GB(B代表字节 1B-8B)
所以我们现在看到的网络视频都必须经过压缩,我们可以压缩几千上万倍仍然很流畅,你不觉得很神奇吗?
能做到这点蕴含很深刻的哲学:通过关注信息增量而不是关注信息存量来极大的提升效率
跨学科_信息论_帧间压缩.jpg
上面是一个人招手分解成每一帧的样子,如果我们对这里面的每一张图进行压缩,这里面很多信息是重复的,例如这个人的身体
除了右手在变化其他部位基本不变,所以我们只需要对第一个图进行整体处理,在接下来的图里面只处理他变化的那只手的信息,
就可以大大减少工作量这就是帧间压缩的精髓
这个算法对我们的启发是关注变化,忽略重复,可以使我们的学习效率提升N倍
经常有同学问我如何读这么多的书,我的回答很简单,天下武功唯快不破,通常情况下,我用休息日读书,每天可以读两到三本新书,
这样如果我想刻意读很多书,一周的休息时间大概能够读十本新书,这大概是一个普通人一年的阅读量也就是说我的最高速度
可能是常人的50倍,但是这并不是故事的全部,我读书的关键原则是不平均用力,读越基础,越深刻,越偏理论的书,花的时间越多,
读越表层,越肤浅越偏应用的书花的时间越少,这就是霍夫曼编码的原理,因为基础的知识在很多的不同的数据里面都会出现,
所以是高频场景就应该配备大量的资源去搞定,所以我读书的方法可以说是霍夫曼编码结合帧间压缩算法的结合,简单来说:
集中精力夯实基础知识+只关注新知识的增量.这样一来随着你啃下的基础知识越来越多,就会发现很多书籍能够提供的新增信息论
其实没有那么多,所以我们只需要集中精力把每本新书提供的最重要的新增信息量全部消化完就能解决问题了
比如你对大脑的分区有一个完整的知识框架,那么你就会发现很多畅销书里面引用脑科学专业知识的那个部分,你读的都非常快,
而对其他人来说那个部分可能是最难读的,再比如有的书会画一些简单函数来说明问题,如果你对最常见的函数形态有个整体的认知
比如说指数函数,对数函数,幂函数,S形函数,那么当你看到相关部分的时候也可以快速理解,所以快速阅读的前提是你的基础知识
一定要先打牢,如果你对很多人类关键的学科知识都建立了认知框架,那么新书的增量阅读也就非常快了.
回到帧压缩的图,对于每一个细分领域,统领全局的第一帧都是必须认认真真处理好的,你处理的越好,基础越扎实,后面做增量的
工作量也就越小,如果跳出读书应用到生活的更多方面,就会发现他进一步给我们的启发是:做任何事情,起步的时候先花时间把基本功
练扎实是重要的,因为基本功越扎实,后面不断前进就可以只关注增量,大大提升效率


互信息(Mutual Information)
两件事情之间的互信息越大就表明他们之间的相关性越强
跨学科_信息论_互信息1.jpg
假设有两个独立发生随机事件,一个叫信春哥,它的信息熵是h(x),一个是不挂科,它的信息熵是h(y),这两个代表信息熵圆圈之间的交集
就是他们的互信息,可以理解为在中间的交叉区域越大,信春哥和不挂科之间的互信息就越大,也就意味着两者之间的相关性越强,补充一下,
相关性并不是因果性,即便信春哥和不挂科之间有着非常高的相关性也不代表信春哥就是不挂科的原因
从信息论角度看他只关心信春哥这件事情到底能够给不挂科这件事情消除多大的不确定性,减少多少信息熵,两个独立事件的相关性是可以通过
严格计算得出来的,只要他们之间的互信息比较高,我们就可以确信他们有相关性,而不需要寻找他们的因果行,这是数据科学给人类的一种非常
重要的思考方法,因为我们人类是一种非常喜欢寻找因果的生物,从孩童时期了解世界最重要的方式就是去寻找原因,回忆一下我们启蒙读物的名字
叫做十万个为什么,你看我们没有把他叫做十万个互信息,十万个相关性,因为研究相关性放弃因果行非常不符合人类的本能,但是在这个世界上
大部分事物之间的联系其实都是相关联系,而不是因果联系,比如现在抖音,B站给我们推荐视频的时候,通常会给不同的用户群打个性化标签,
比如宝妈,学生党,数码爱好者,军事迷等等,他们使用的就是互信息,因为不能说你打开了一个军事题材的视频就说你是个军迷,即便你一直在看
军事题材,也有可能你根本不是军迷,只是这段时间写论文需要用到,也可能是你表弟经常使用你的电脑,所以你的浏览行为并不能说明你是谁,
但他就可以说明这个账号和某一类题材有高相关性,其实很多成功人士在分享自己经验时也都混淆了相关和因果,比如有的人会说当年之所以进入
这个领域或者当年之所以做某件事请是因为我觉得XXX,这个说法通常都是错的,就是典型的把相关性当成因果性,因为生活是错综复杂的
而记忆却是主观的,在认知心理学讲过,再加上人类在表达自己的时候非常容易美化自己,故意忽略某些不能说的东西,所以简单归因通常都是
很难还原真相的,比如过去30年,很多中国企业家觉得自己成功是因为勤奋吃苦,有战略有勇敢,有没有关系呢?有.是不是因果关系呢?不见得.
毕竟有的重要原因是很多人没有意识到的,就中国本身有整体的高发展红利,国家通过长期汇率控制,增发货币,投资基础设施,这实际上为大量的
企业主创造了远胜于其他发展中国家的生存环境,所以很多人成功的原因其实非常复杂,无法追溯,这其实就是真实世界里面很多事物因果
关系的常态,很多事情我们永远无法解释它的成因,但是我们可以使用信息论和数据科学去分析万事万物间的关联性,这就是科学最迷人的地方
因为他可量化,可证伪,清楚自己干不了什么,也清楚自己能干什么.

高互信息的一个极端情况就是信息等价,意思是只要知道了事件A发生的信息就等同于知道谁看B发生的信息
跨学科_信息论_信息等价.jpg
比如前面的盒子,他把皮卡丘的样子非常清晰的印在盒子外面,这就是一个比较接近于提供等价信息的例子,这个例子不够等价的例子在哪里呢?
在于盒子印出来的是二维的动画照片,而不是真实的三维照片
再比如我们日常生活中的说废话,其实也是因为前后两句话提供的等价信息或者说互信息很高,比如我说今天天气真好,蓝天白云,风和日丽,
阳光明媚,来分析一下这四个词的互信息:
天气好很大概率就是阳光明媚,所以这两者之间几乎等价,阳光明媚很大概率就是风和日丽,这两者之间也几乎等价,所以这三个词之间的互信息
就很高,而说一堆互信息很高的词就会让听众觉得是废话连篇,相对而言,蓝天白云这个词,其实提供了额外的信息量了,因为天气好有可能是
万里无云,蓝天白云这个词进一步界定了天气好的细分情况,也就减少了我们了解真实天气情况的信息熵


冗余度(Redundancy)
如果你说话废话多,那么就是你添加了很多的冗余度,但是也有好的一方面,在信息论,计算机科学,工程学都有出现
简单说他讲的是资源的重复度,在计算机科学里面冗余技术是通过增加多余的设备或者备份来保证系统更加安全可靠工作的一种方法,注意,这里
冗余是故意实施的策略,比如淘宝或微信这样的软件他们的数据中心为了保证运行顺畅,通常都会有额外备份的服务器,或者备用电源等等,
而冗余备份最经典的例子其实是区块链,为了保证不可篡改,他们把冗余这件事做到了极致,在我们的世界里故意安排冗余的例子有很多
比如越野车的备用轮胎,大厦的防火安全通道,大商场安装的额外发电机,飞机上的双引擎设计
说回信息论在我们传达信息的过程中废话或者重复信息其实是有必要的存在,因为如果冗余度太低就会增加人类接收信息的难度,
我们的大脑设计并不是用来接收高密度信息的,我们需要呼吸,会走神,接收信息的过程经常需要停顿,所以我们接收的信息完全没有冗余度,
就会导致我们一旦走神马上就会丢掉必要的信息,只能够不断的回头去重新阅读,这就回导致额外的痛苦,比如人类就会觉得读小说
比读论文轻松很多,就是因为小说的冗余度要高很多,再比如我们喜欢听故事而不是听抽象理论,其实也是因为故事提供了更高的冗余度,
最经典的还是标点符号,我们停下来想2秒钟,大家觉得标点符号提供的信息量大不大,那肯定是不大了,你不能说它没有提供任何信息量,
比如说感叹号提供了一种额外的情绪信息,但是最常出现的逗号和句号,其实信息量非常小.要知道机器读文章就是不需要标点符号了,
但是人类却很难接收完全没有标点符号的长文章,所以冗余信息的存在就是为人类设计的,但是很明显冗余度不是越高越好.
他应该有个度,因人而异,大家经常在网上看一些知识科普视频,一开始总爱讲背景知识,花费大量的时间,十分钟的视频,一两个核心观点,
看了半天,也没有看到这个观点的实质内容,这个让我们感觉内容兑水很严重,但是同一个视频如果一个年纪很大的阿姨去听,她可能会
听的津津有味,而且还觉得讲的很有道理,这种差异跟代际更迭有很大的关系,我们这代人出生在信息时代,在童年就接受了大量的
信息训练,所以大脑前额叶皮质负责分析和理解信息的脑区,是比前几代人都要发达了,这意味着我们能接受更高密度的信息内容,
其实随着信息科技的发展,人类对冗余的容忍度也在变得越来越低,这也能解释为什么年轻一代沟通过程中类似yyds,xswl,zqsg,nbcs,
这种高信息密度的简写会这么流行.
了解冗余度对我们的启发:
1.冗余并不一定是坏东西,在工程领域,他可以保证系统运作安全,在表达上,他能更好的服务于人类的认知习惯
2.时代在进步,人类习惯接受的冗余度也在减少,所以我们越来越需要掌握去除冗余度的方法
那么我们如何成为高密度信息的掌握者呢?
前面已经通过压缩算法解释了快速阅读的方法,这里再补充一点去除冗余信息的方法,答案就是画分析框架.
我这里说的分析框架并不是常见的脑图,其实脑图只是一种偷懒的框架,它的默认结构就是只有金字塔结构,但是我们在语言表达模型的课讲过
结构是多种多样的,比如递进,循环,四象限等等,所以我们的确应该掌握更多的框架模型.
up主画分析框架通常使用这样的三步法:
1.先把关键概念零散列出来,这种罗列不需要顺序,只要觉得重要就写上去,这一步就类似于建立了很多概念的卡片
2.寻找概念卡片之间的关联,对他们进行分类,连接,同时拿掉一些信息等价的卡片
3.套用和矫正  会议我在大脑中已经建立的那些思维模型,然后对他们进行套用和矫正,最后形成一个属于这一次阅读内容的新的分析框架,

我发现通过这个方法,我可以把一份几十页的研报简写成一张大图,让记忆的效率提高很多,进一步讲,这张大图又能够成为未来
解读更多研报的底层基础,就像前面讲过的关键第一帧,有了它我就可以加速理解相关行业的其他研报,因为我只要重点关注这些
研报的增量信息就行了




Brewnut
最后说的分析框架步骤很像卡片式学习笔记写作法
还有个类似的app，叫flomo，用起来不错，可以记录很多零碎的概念，然后每次记录可以用标签去产生关联，后续写成文章或成为自己的体系就很快

todo 卡片式学习笔记