https://zhuanlan.zhihu.com/p/43526907
https://blog.csdn.net/u012988901/article/details/111313057#t9
https://zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C

内存屏障 Memory Barrier  也称内存栅栏，内存栅障，屏障指令等
它使得 CPU 或编译器在对内存进行操作的时候, 严格按照一定的顺序来执行, 也就是说在内存屏障之前的指令和之后的指令不会由于系统优化等原因而导致乱序。
大多数现代计算机为了提高性能而采取乱序执行，这使得内存屏障成为必须。

是一个CPU指令，它的作用有两个，一是保证特定操作的执行顺序，二是保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）。
由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能
和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。
Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本

https://www.jianshu.com/p/2ab5e3d7e510
硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障
对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；
对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见
指令重排中Load和Store两种操作会有Load-Store、Store-Load、Load-Load、Store-Store这四种可能的乱序结果。
java的内存屏障组合
LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。
   它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能
JMM中volatile的指令顺序  https://juejin.cn/post/7032699785949741092#heading-6
普通读  普通写  StoreStore(禁止上面的普通写与volatile写重排)  volatile写  StoreLoad(禁止上面的volatile写与下面可能的volatile读写重排序)
volatile读 LoadLoad(禁止下面所有普通读和上面的volatile读重排)   LoadStore(禁止下面所有普通写操作和上面的volatile读重排序)  普通读  普通写
jvm_volatile_命令读写.webp
volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态：
由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性


不同的硬件平台实现内存屏障的手段并不是一样，上层语言可能进行封装屏蔽细节
Intel为此提供三种内存屏障指令：
sfence ，实现Store Barrior 会将store buffer中缓存的修改刷入L1 cache中，使得其他cpu核可以观察到这些修改，
   而且之后的写操作不会被调度到之前，即sfence之前的写操作一定在sfence完成且全局可见；
lfence ，实现Load Barrior 会将invalidate queue失效，强制读取入L1 cache中，而且lfence之后的读操作不会被调度到之前，
   即lfence之前的读操作一定在lfence完成（并未规定全局可见性）；
mfence ，实现Full Barrior 同时刷新store buffer和invalidate queue，保证了mfence前后的读写操作的顺序，
  同时要求mfence之后写操作结果全局可见之前，mfence之前写操作结果全局可见；
lock 用来修饰当前指令操作的内存只能由当前CPU使用，若指令不操作内存仍然由用，因为这个修饰会让指令操作本身原子化，
   而且自带Full Barrior效果；还有指令比如IO操作的指令、exch等原子交换的指令，任何带有lock前缀的指令以及CPUID等指令都有内存屏障的作用


X86-64下仅支持一种指令重排：Store-Load ，即读操作可能会重排到写操作前面，同时不同线程的写操作并没有保证全局可见，
例子见《Intel® 64 and IA-32 Architectures Software Developer’s Manual》手册8.6.1、8.2.3.7节。要注意的是这个问题只能用mfence解决，
不能靠组合sfence和lfence解决。（用sfence+lfence组合仅可以解决重排问题，但不能解决全局可见性问题，
简单理解不如视为sfence和lfence本身也能乱序重拍）
https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf


X86-64一般情况根本不会需要使用lfence与sfence这两个指令，除非操作Write-Through内存或使用 non-temporal 指令（NT指令，属于SSE指令集），
比如movntdq, movnti, maskmovq，这些指令也使用Write-Through内存策略，通常使用在图形学或视频处理，
Linux编程里就需要使用GNC提供的专门的函数（例子见参考资料13：Memory part 5: What programmers can do）
//todo write-through

为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？
https://zhuanlan.zhihu.com/p/81555436


下面是GNU中的三种内存屏障定义方法，结合了编译器屏障和三种CPU屏障指令
```
#define lfence() __asm__ __volatile__("lfence": : :"memory")
#define sfence() __asm__ __volatile__("sfence": : :"memory")
#define mfence() __asm__ __volatile__("mfence": : :"memory")
```

代码中仍然使用lfence()与sfence()这两个内存屏障应该也是一种长远的考虑。按照Interface写代码是最保险的，
  万一Intel以后出一个采用弱一致模型的CPU，遗留代码出问题就不好了。目前在X86下面视为编译器屏障即可。

GCC 4以后的版本也提供了Built-in的屏障函数__sync_synchronize()，这个屏障函数既是编译屏障又是内存屏障，
  代码插入这个函数的地方会被安插一条mfence指令。

C++11为内存屏障提供了专门的函数std::atomic_thread_fence，方便移植统一行为而且可以配合内存模型进行设置，比如实现Acquire-release语义：
```
#include <atomic>
std::atomic_thread_fence(std::memory_order_acquire);
std::atomic_thread_fence(std::memory_order_release);
```



如何理解 C++11 的六种 memory order
https://www.zhihu.com/question/24301047

Memory Model: 从多处理器到高级语言
https://github.com/GHScan/TechNotes/blob/master/2017/Memory_Model.md

LINUX内核内存屏障 (Documentation/memory-barriers.txt)
https://blog.csdn.net/carltraveler/article/details/39055321

高并发编程--多处理器编程中的一致性问题
https://zhuanlan.zhihu.com/p/48157076

聊聊原子变量、锁、内存屏障那点事
https://www.0xffffff.org/2017/02/21/40-atomic-variable-mutex-and-memory-barrier/


https://zhuanlan.zhihu.com/p/75509358
顺序一致性与JMM
顺序一致性的内存模型
顺序一致性内存模型是可见性和有序性强有力的保证，是一个严格的内存模型。假设 Java 内存模型是顺序一致性的，
那么许多编译器层面和CPU层面的优化将无法施展，虽然顺序一致性虽然能解决很多并发层面的诡异问题，但是由于束缚了性能优化的施展空间，
其并不适合 Java。

https://en.wikipedia.org/wiki/Memory_ordering
内存一致性
Sequential consistency (all reads and all writes are in-order)  顺序一致性   所有的读写是有序的
Relaxed consistency (some types of reordering are allowed)    松散一致性   可能发生重排
Loads can be reordered after loads (for better working of cache coherency, better scaling)
Loads can be reordered after stores
Stores can be reordered after stores
Stores can be reordered after loads
Weak consistency (reads and writes are arbitrarily reordered, limited only by explicit memory barriers) 
   弱一致性   读写任意排序，受显式的内存屏障限制

WMO Weak memory order    weak ordered  
TSO Total store order    strong ordered
RMO Relaxed-memory order  松散内存顺序
PSO Partial store order  部分存储顺序
不同处理器允许的重排序
https://en.wikipedia.org/wiki/Memory_ordering
Memory ordering in some architectures

不同处理器允许手动刷新读写
x86
```
lfence (asm), void _mm_lfence(void)
sfence (asm), void _mm_sfence(void)[11]
mfence (asm), void _mm_mfence(void)
```
arm
```
dmb (asm)
dsb (asm)
isb (asm)
```